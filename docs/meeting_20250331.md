

TODO:
- DBE-KT22
    - how do we handle HTML code in text?
    - which 6 questions to delete? (LLaSA has 206, we 212)
    - what to do with students that answered questions multiple times? Keep all or keep only the first?
- example selector: studentid_semantic
    - how to handle the case when the student is not in the database?
    - how to handle the case when the exercises for a student is lower than k?
    - is it ok to embed once for every question_id and fine corresponding interactions? (instead of interaction_id)
- langfuse
    - scores -> does Kate know how to get per-observation scores?
- Pinecode
    - which embedding models for gpt4o, claude 3.5/3.7 and olmo2?
    - do they need my pinecode API or can I add them to some team?
- example formatter
    - example formatter with quotes
- CUPA & FCE
    - how to link datasets?
- IRT estimation
    - how to use it (find students with similar student ability?)?
    - is this a separate selector (find similar students) and can this be a backup for another selector if the exact student is not in the database?
- API tokens
    - you need to create .env file with OpenAI, langfuse and pinecode tokens
    - I need to get Anthropic token
- models
    - always temperature 0.0?



DONE:
- new dataset format with 2 files with strict column names: questions.csv and interactions.csv
- langfuse tracing (with scores)
- Luca added IRT estimation
- make structured output JSON class dynamic
- add time to experiment name in /output folder
- DBE-KT22
    - filtered DBE-KT22 dataset to only include students who answered all questions (like LLaSA paper)
    - cleaned latex code in DBE-KT22 dataset (was an html link with latex code in it)
- implemented creating and loading hard split train/val/test with valsmall and vallarge -> can be shared with you
- implemented semantic similarity with Pinecode vector DB (for now, llama3 with DBE-KT22)
- implemented new prompt template with user1 and user2 messages
- 
