DONE:
- embedding model:
    - add as configuration parameter (does not need to be linked to the model)
    - add openai embedding model
- use pip venv instead of conda
- Add user guide for contributing and example.env
- Add F1-score



TODO:
- Why is discrimination range [+1, +1] in IRT estimation? (link)
- Configurations:
    - @Kate: comments on the configurations workflow?
    - Can we use langsmith playground? (see docs; I think it is difficult to bring the student history examples in here)
    - can we define which yacs registry options to use and then builds all the combinations automatically?
    - do we have some kind of prompt engineering baseline score (e.g., Luca's zero-shot reference prompt from the EMNLP paper)?
- Do we use GPT-4.1?
- Do we start at calculating final difficulty with IRT or do we first focus on replicating student behaviour?
- Try not to merge questions.csv and interactions.csv datasets -> necessary because CUPA and CFE datasets cannot be joined on some key
- How do we handle roleplaying? How many times do we ask an LLM response per test set question?



