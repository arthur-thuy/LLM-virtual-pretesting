{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "\n",
    "from tools.data_manager import CupaDatamanager\n",
    "from tools.constants import WRITE_DIR, DICT_CEFR_DESCRIPTIONS\n",
    "\n",
    "# Reload the variables in your '.env' file (override the existing variables)\n",
    "dotenv.load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cupa_data_dir = \"../data/raw/CUPA\"\n",
    "cupa_dm = CupaDatamanager()\n",
    "dataset = cupa_dm.get_cupa_dataset(cupa_data_dir, WRITE_DIR, save_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_format_input(row) -> str:\n",
    "    return f\"Context:\\n{row.context}\\nQuestion: {row.question}\\nOptions:\\n1. {row.option_0}\\n2. {row.option_1}\\n3. {row.option_2}\\n4. {row.option_3}\"\n",
    "\n",
    "def human_format_output(row) -> str:\n",
    "    return f\"Question difficulty: {row.difficulty}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_df = pd.DataFrame()\n",
    "examples_df[\"input\"] = dataset[\"train\"].apply(human_format_input, axis=1)\n",
    "examples_df[\"output\"] = dataset[\"train\"].apply(human_format_output, axis=1)\n",
    "examples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with first 20 examples\n",
    "examples_df = examples_df.head(20)\n",
    "few_shot_list = [{\"input\": row[\"input\"], \"output\": row[\"output\"]} for _, row in examples_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example selector\n",
    "\n",
    "NOTE: I need OpenAI credits to use the OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = few_shot_list\n",
    "# to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_selector = SemanticSimilarityExampleSelector(\n",
    "#     vectorstore=vectorstore,\n",
    "#     k=2,\n",
    "# )\n",
    "\n",
    "# # The prompt template will load examples by passing the input do the `select_examples` method\n",
    "# example_selector.select_examples({\"input\": \"horse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        random_match = random.choice(self.examples)\n",
    "        return [random_match]\n",
    "\n",
    "example_selector = RandomExampleSelector(examples=few_shot_list)\n",
    "example_selector.select_examples({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = PromptTemplate.from_template(\n",
    "    \"You are a student working on {exam_type}, containing multiple choice questions. \"\n",
    "    \"You will be asked to provide the difficulty level of the question.\"\n",
    ")\n",
    "\n",
    "system_prompt_input = system_prompt_template.format(exam_type=\"an English reading comprehension exam\")\n",
    "system_prompt_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.invoke(input=\"What's 3 ðŸ¦œ 3?\").to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_input),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(final_prompt.invoke(input=\"What's 3 ðŸ¦œ 3?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use with a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = {\"input\": examples_df.loc[21, \"input\"]}\n",
    "test_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "chain.invoke(test_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Ask to find zero-shot misconceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_template = PromptTemplate.from_template(\n",
    "    \"You are a student working on {exam_type}, containing multiple choice questions. \"\n",
    "    \"You are currently at CEFR level {level}, which means that you {level_description} \"\n",
    "    \"What misconceptions could you have about the question that could lead to answering it incorrectly? \"\n",
    "    \"For each answer option, explain the possible misconception that could lead to selecting that option. \"\n",
    "    \"Furthermore, provide the answer that you think is correct (as an integer in the range 1-4).\"\n",
    ")\n",
    "\n",
    "system_prompt_input = system_prompt_template.format(\n",
    "    exam_type=\"an English reading comprehension exam\",\n",
    "    level=\"B2\",\n",
    "    level_description=DICT_CEFR_DESCRIPTIONS[\"B2\"],\n",
    ")\n",
    "system_prompt_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = {\"input\": examples_df.loc[21, \"input\"]}\n",
    "test_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_input),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(final_prompt.invoke(input=\"What's 3 ðŸ¦œ 3?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic\n",
    "class MCQAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of an multiple-choice question.\"\"\"\n",
    "\n",
    "    option_1: str = Field(description=\"Misconception in option 1\")\n",
    "    option_2: str = Field(description=\"Misconception in option 2\")\n",
    "    option_3: str = Field(description=\"Misconception in option 3\")\n",
    "    option_4: str = Field(description=\"Misconception in option 4\")\n",
    "    student_answer: int = Field(\n",
    "        description=\"The student's answer to the question, as an integer (1-4)\"\n",
    "    )\n",
    "    # difficulty: str = Field(description=\"The difficulty level of the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0).with_structured_output(\n",
    "    MCQAnalysis\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "test_output = chain.invoke(test_example)\n",
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.1,\n",
    ").with_structured_output(MCQAnalysis)\n",
    "chain = final_prompt | model\n",
    "\n",
    "test_output = chain.invoke(test_example)\n",
    "test_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_virtual_pretesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
