{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abthuy/anaconda3/envs/llm_virtual_pretesting/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "# /\n",
    "\n",
    "# related third party imports\n",
    "import structlog\n",
    "\n",
    "# local application/library specific imports\n",
    "from tools.configurator import (\n",
    "    get_configs_out,\n",
    "    get_config_ids,\n",
    ")\n",
    "from tools.analyzer import (\n",
    "    print_table_from_dict,\n",
    "    get_results_dict,\n",
    "    merge_all_results,\n",
    "    create_config_id_print,\n",
    ")\n",
    "\n",
    "\n",
    "logger = structlog.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "EXP_NAME = \"experiment_20250318\"\n",
    "CONFIG_ID = \"llama3_TEMP0.5\"\n",
    "EXCLUDE_METRICS = []\n",
    "LEGEND_EXACT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG2LEGEND_DICT = {\n",
    "    \"llama3_TEMP0.5_FEW3\": \"LLama3 (3-shot, temp 0.5)\",\n",
    "    \"olmo2:7b_TEMP0.5_FEW3\": \"Olmo2 (3-shot, temp 0.5)\",\n",
    "}\n",
    "\n",
    "# TODO: currently not used but might be useful\n",
    "METRIC2LEGEND_DICT = {\n",
    "    \"acc_student_pred\": \"Accuracy LLM -> student\",\n",
    "    \"acc_true_student\": \"Accuracy student -> true\",\n",
    "    \"acc_true_pred\": \"Accuracy LLM -> true\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_configs_out(EXP_NAME)\n",
    "config_ids = get_config_ids(configs)\n",
    "config_dict = {config_id: cfg for config_id, cfg in zip(config_ids, configs)}\n",
    "\n",
    "CONFIG2LEGEND_DICT = {\n",
    "    config_id: create_config_id_print(config_id) for config_id in config_ids\n",
    "}\n",
    "legend_kwargs = {\n",
    "    \"config2legend\": CONFIG2LEGEND_DICT,\n",
    "    \"legend_exact\": LEGEND_EXACT,\n",
    "    \"metric2legend\": METRIC2LEGEND_DICT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMerging runs [1] in: output/experiment_20250318/llama3~T0.0~Srandom~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMerging runs [1] in: output/experiment_20250318/olmo2:7b~T0.0~Sstudentid_random~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMerging runs [1] in: output/experiment_20250318/llama3~T0.0~Sstudentid_random~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mMerging runs [1] in: output/experiment_20250318/olmo2:7b~T0.0~Srandom~F3.pickle\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# merge results for all configs\n",
    "run_id_dict = merge_all_results(EXP_NAME, config_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoading checkpoint            \u001b[0m \u001b[36moutput_path\u001b[0m=\u001b[35moutput/experiment_20250318/llama3~T0.0~Srandom~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoading checkpoint            \u001b[0m \u001b[36moutput_path\u001b[0m=\u001b[35moutput/experiment_20250318/olmo2:7b~T0.0~Sstudentid_random~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoading checkpoint            \u001b[0m \u001b[36moutput_path\u001b[0m=\u001b[35moutput/experiment_20250318/llama3~T0.0~Sstudentid_random~F3.pickle\u001b[0m\n",
      "\u001b[2m2025-03-19 11:24:25\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mLoading checkpoint            \u001b[0m \u001b[36moutput_path\u001b[0m=\u001b[35moutput/experiment_20250318/olmo2:7b~T0.0~Srandom~F3.pickle\u001b[0m\n",
      "+-----------------------------------------------+---------------------------+----------------------------+------------------------+----------------+\n",
      "| Config                                        | Accuracy LLM -> student   | Accuracy student -> true   | Accuracy LLM -> true   | prop_invalid   |\n",
      "|-----------------------------------------------+---------------------------+----------------------------+------------------------+----------------|\n",
      "| llama3 (random, 3-shot, temp 0.0)             | 0.759 ± nan               | 0.772 ± nan                | 0.963 ± nan            | 0.000 ± nan    |\n",
      "| olmo2:7b (studentid_random, 3-shot, temp 0.0) | 0.722 ± nan               | 0.772 ± nan                | 0.921 ± nan            | 0.034 ± nan    |\n",
      "| llama3 (studentid_random, 3-shot, temp 0.0)   | 0.759 ± nan               | 0.772 ± nan                | 0.966 ± nan            | 0.003 ± nan    |\n",
      "| olmo2:7b (random, 3-shot, temp 0.0)           | 0.722 ± nan               | 0.772 ± nan                | 0.911 ± nan            | 0.039 ± nan    |\n",
      "+-----------------------------------------------+---------------------------+----------------------------+------------------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abthuy/Documents/PhD research/LLM-virtual-pretesting/src/tools/analyzer.py:63: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  stderror = scipy.stats.sem(ary, ddof=1, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "results_dict = get_results_dict(\n",
    "    exp_name=EXP_NAME,\n",
    "    config_ids=config_ids,\n",
    "    run_id=None,\n",
    ")\n",
    "print_table_from_dict(\n",
    "    eval_dict=results_dict,\n",
    "    exp_name=EXP_NAME,\n",
    "    exclude_metrics=EXCLUDE_METRICS,\n",
    "    decimals=3,\n",
    "    **legend_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_virtual_pretesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
