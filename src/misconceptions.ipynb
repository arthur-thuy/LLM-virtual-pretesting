{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "# related third party imports\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from yacs.config import CfgNode\n",
    "\n",
    "# local application/library specific imports\n",
    "from example_selector.example_selector import (\n",
    "    RandomExampleSelector,\n",
    "    StudentIDExampleSelector,\n",
    ")\n",
    "from data_loader.data_loader import DataLoader\n",
    "from tools.constants import SILVER_DIR, TRAIN, VALIDATION, TEST\n",
    "from prompt_template.example_prompt import (\n",
    "    df_to_listdict,\n",
    "    human_format_input,\n",
    "    human_format_output,\n",
    "    apply_prompt_fmt,\n",
    ")\n",
    "from model.build import build_model\n",
    "\n",
    "# Reload the variables in your '.env' file (override the existing variables)\n",
    "dotenv.load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_STRUCTURED_OUTPUT = {\n",
    "    \"llama3\": False,\n",
    "    \"llama3.2\": True,\n",
    "    \"olmo2:7b\": False,\n",
    "    \"gpt-4o\": True,\n",
    "    \"gpt-4o-mini\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUTS ###\n",
    "MODEL_NAME = \"olmo2:7b\"  # \"llama3\"  # \"gpt-4o-mini\"  # \"llama3.2\"\n",
    "MODEL_PROVIDER = \"ollama\"  # \"openai\"  # \n",
    "SUPPORTS_STRUCTURED_OUTPUT = MODEL_STRUCTURED_OUTPUT[MODEL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = CfgNode(\n",
    "    {\n",
    "        \"NAME\": MODEL_NAME,\n",
    "        \"PROVIDER\": MODEL_PROVIDER,\n",
    "        \"TEMPERATURE\": 0.5,\n",
    "        \"FORMAT\": \"json\",\n",
    "        \"MAX_TOKENS\": None,\n",
    "        \"TIMEOUT\": None,\n",
    "        \"MAX_RETRIES\": None,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-03-18 11:59:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSet seed (42)                 \u001b[0m\n",
      "\u001b[2m2025-03-18 11:59:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCreating train split          \u001b[0m \u001b[36mnum_interactions\u001b[0m=\u001b[35m6107\u001b[0m\n",
      "\u001b[2m2025-03-18 11:59:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCreating validation split     \u001b[0m \u001b[36mnum_interactions\u001b[0m=\u001b[35m1528\u001b[0m\n",
      "\u001b[2m2025-03-18 11:59:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCreating test split           \u001b[0m \u001b[36mnum_interactions\u001b[0m=\u001b[35m2546\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(read_dir=SILVER_DIR, dataset_name=\"dbe_kt22\")\n",
    "dataset = data_loader.split_data(train_size=0.6, test_size=0.25, seed=42)\n",
    "\n",
    "# dataframes\n",
    "df_train = apply_prompt_fmt(\n",
    "    df=dataset[TRAIN], input_fmt=human_format_input, output_fmt=human_format_output\n",
    ")\n",
    "df_val = apply_prompt_fmt(\n",
    "    df=dataset[VALIDATION], input_fmt=human_format_input, output_fmt=human_format_output\n",
    ")\n",
    "df_test = apply_prompt_fmt(\n",
    "    df=dataset[TEST], input_fmt=human_format_input, output_fmt=human_format_output\n",
    ")\n",
    "\n",
    "# list of dicts\n",
    "list_train = df_to_listdict(df_train)\n",
    "list_val = df_to_listdict(df_val)\n",
    "list_test = df_to_listdict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example selector\n",
    "\n",
    "NOTE: I need OpenAI credits to use the OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = few_shot_list\n",
    "# to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "# vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_selector = SemanticSimilarityExampleSelector(\n",
    "#     vectorstore=vectorstore,\n",
    "#     k=2,\n",
    "# )\n",
    "\n",
    "# # The prompt template will load examples by passing the input do the `select_examples` method\n",
    "# example_selector.select_examples({\"input\": \"horse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the selector with k=3 for 3-shot prompting\n",
    "# example_selector = RandomExampleSelector(examples=list_train, k=3)\n",
    "# example_selector.select_examples({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'Question:\\nConsider the following two transactions <img src=\"http://latex.codecogs.com/gif.latex?T_{1}\" border=\"0\"/> and <img src=\"http://latex.codecogs.com/gif.latex?T_{2}\" border=\"0\"/>, which transfer money between\\r\\ndifferent accounts. If the transaction isolation level is “read uncommitted”, which of the\\r\\nfollowing schedules is not serializable?<br>\\r\\n<html>\\r\\n<head>\\r\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\r\\n<style>\\r\\n* {\\r\\n  box-sizing: border-box;\\r\\n}\\r\\n.column {\\r\\n  float: left;\\r\\n  width: 20%;\\r\\n  padding:9px;\\r\\n  height: 400px; \\r\\n}\\r\\n.row:after {\\r\\n  content: \"\";\\r\\n  display: table;\\r\\n  clear: both;\\r\\n}\\r\\n</style>\\r\\n</head>\\r\\n<body>\\r\\n<div class=\"row\"display= \"table\">\\r\\n  <div class=\"column\" >\\r\\n    <h2>1</h2>\\r\\n   <table style=\"padding: 20px;text-align: center;width: 90%;\" border=\"1\">\\r\\n\\r\\n  <tr>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{1}\" border=\"0\"/></th>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{2}\" border=\"0\"/></th>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td> read(A) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td> A=A-10</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n <tr>\\r\\n    <td> write(A)</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n\\r\\n<tr>\\r\\n    <td> read(B) </td>\\r\\n    <td>  </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> B=B+10 </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>write(B)  </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>commit  </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td> read(B)</td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>B=B-20 </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>write(B) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>read(D) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>D=D+20 </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>write(D) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>commit </td>\\r\\n  </tr>\\r\\n</table>\\r\\n  </div>\\r\\n  <div class=\"column\" >\\r\\n    <h2>2</h2>\\r\\n<table style=\"padding: 20px;text-align: center;width: 90%;\" border=\"1\">\\r\\n\\r\\n  <tr>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{1}\" border=\"0\"/></th>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{2}\" border=\"0\"/></th>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td> read(A) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td> </td>\\r\\n    <td>read(B) </td>\\r\\n  </tr>\\r\\n <tr>\\r\\n    <td> A=A-10</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>  B=B-20</td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> write(A) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>write(B) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>read(B) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td> read(D)</td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  B=B+10</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> write(B) </td>\\r\\n    <td></td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> commit </td>\\r\\n    <td></td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>D=D+20 </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>write(D) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>commit </td>\\r\\n  </tr>\\r\\n</table>\\r\\n  </div>\\r\\n<div class=\"column\" >\\r\\n    <h2>3</h2>\\r\\n   <table style=\"padding: 20px;text-align: center;width: 90%;\" border=\"1\">\\r\\n\\r\\n  <tr>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{1}\" border=\"0\"/></th>\\r\\n    <th><center><img src=\"http://latex.codecogs.com/gif.latex?T_{2}\" border=\"0\"/></th>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td> read(A) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n  <tr>\\r\\n    <td>A=A-10 </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n <tr>\\r\\n    <td> </td>\\r\\n    <td>read(B) </td>\\r\\n  </tr>\\r\\n\\r\\n<tr>\\r\\n    <td>  write(A)</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> read(B) </td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>B=B-20 </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> </td>\\r\\n    <td> write(B)</td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  B=B+10</td>\\r\\n    <td> </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>read(D) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> write(B) </td>\\r\\n    <td></td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td> commit </td>\\r\\n    <td></td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>D=D+20 </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>write(D) </td>\\r\\n  </tr>\\r\\n<tr>\\r\\n    <td>  </td>\\r\\n    <td>commit </td>\\r\\n  </tr>\\r\\n</table>\\r\\n  </div>\\r\\n</div>\\r\\n</body>\\r\\n</html>\\r\\n\\n\\nOptions:\\n1. Schedule 2\\n2. Schedule 1\\n3. Schedule 3\\n4. None of 1, 2 and 3\\n\\nCorrect answer: 3',\n",
       "  'output': 'Student answer: 2',\n",
       "  'student_id': 395},\n",
       " {'input': 'Question:\\nIf A = {2, 3, 4, 5}, B = {4, 5, 6, 7}, C = {6, 7, 8, 9}, D = {8, 9, 10, 11}, then (A ∪ B) ∪ C=_________.\\n\\nOptions:\\n1. {1, 4, 9, 7,8,11,10}\\n2. {4, 5,7,8,9,10,11}\\n3. {2, 4, 5, 9, 10, 11, 8}\\n4. {2, 3, 4, 5, 6, 7, 8, 9}\\n\\nCorrect answer: 4',\n",
       "  'output': 'Student answer: 4',\n",
       "  'student_id': 395},\n",
       " {'input': 'Question:\\nThe cardinality of a set is the number of elements of the set. What is the cardinality of the set of odd positive integers less than 10?\\n\\nOptions:\\n1. 10\\n2. 20\\n3. 5\\n4. 3\\n\\nCorrect answer: 3',\n",
       "  'output': 'Student answer: 3',\n",
       "  'student_id': 395}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select examples of a specific student\n",
    "example_selector = StudentIDExampleSelector(examples=list_train, k=3)\n",
    "example_selector.select_examples({\"student_id\": 395})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic\n",
    "class MCQAnswer(BaseModel):\n",
    "    \"\"\"Answer to a multiple-choice question.\"\"\"\n",
    "\n",
    "    explanation: str = Field(\n",
    "        description=\"Misconception if incorrectly answered; motivation if correctly answered\"\n",
    "    )\n",
    "    student_answer: int = Field(\n",
    "        description=\"The student's answer to the question, as an integer (1-4)\"\n",
    "    )\n",
    "    # difficulty: str = Field(description=\"The difficulty level of the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[HumanMessage(content='Question:\\nThe order of tuples in a relation is ____. The order of attributes in a relation is _________.\\n\\nOptions:\\n1. Not important; Not important\\n2. Important; Important\\n3. Not important; Important\\n4. Important; Not important\\n\\nCorrect answer: 3', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 3', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\nIf A = {2, 3, 4, 5}, B = {4, 5, 6, 7}, C = {6, 7, 8, 9}, D = {8, 9, 10, 11}, then A - B=___________.\\n\\nOptions:\\n1. {2,3}\\n2. {2,3,4,5}\\n3. {4,5,6,7}\\n4. {6,7}\\n\\nCorrect answer: 1', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 1', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\nIf A × B = {(p, x), (p, y), (q, x), (q, y)}, then A = _____and B = ______.\\n\\nOptions:\\n1. A = {p, q, x} and B = { y}\\n2. A = {p} and B = {q, x, y}\\n3. A ={x, y} and B = {p, q}\\n4. A = {p, q} and B = {x, y}\\n\\nCorrect answer: 4', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 4', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"student_id\"],\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "out = few_shot_prompt.invoke(input=list_val[0]).to_messages()\n",
    "print(len(out))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a student working on a database systems exam (Department of Computer Science), containing multiple choice questions. You are shown a set of questions that you answered earlier in the exam, together with the correct answers and your student answers. Analyse your responses to the questions and identify the possible misconceptions that led to answering incorrectly. Inspect the new question and think how you would answer it as a student. If you answer incorrectly, explain which misconception leads to selecting that answer. If you answer correctly, explain why you think the answer is correct. Provide your answer as an integer in the range 1-4. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Answer to a multiple-choice question.\", \"properties\": {\"explanation\": {\"description\": \"Misconception if incorrectly answered; motivation if correctly answered\", \"title\": \"Explanation\", \"type\": \"string\"}, \"student_answer\": {\"description\": \"The student's answer to the question, as an integer (1-4)\", \"title\": \"Student Answer\", \"type\": \"integer\"}}, \"required\": [\"explanation\", \"student_answer\"]}\n",
      "```\n",
      "Human: Question:\n",
      "If A × B = {(p, x), (p, y), (q, x), (q, y)}, then A = _____and B = ______.\n",
      "\n",
      "Options:\n",
      "1. A = {p, q, x} and B = { y}\n",
      "2. A = {p} and B = {q, x, y}\n",
      "3. A ={x, y} and B = {p, q}\n",
      "4. A = {p, q} and B = {x, y}\n",
      "\n",
      "Correct answer: 4\n",
      "AI: Student answer: 4\n",
      "Human: Question:\n",
      "Which of the following two sets are equal?\n",
      "\n",
      "Options:\n",
      "1. A = {1, 2, 4} and B = {1, 2, 3}\n",
      "2. A = {1, 2, 3} and B = {2, 1, 3}\n",
      "3. A = {1, 2} and B = {1, 2, 3}\n",
      "4. A = {1, 2} and B = {1}\n",
      "\n",
      "Correct answer: 2\n",
      "AI: Student answer: 2\n",
      "Human: Question:\n",
      "What is the Cartesian product of A = {1, 2} and B = {a, b}?\n",
      "\n",
      "Options:\n",
      "1. {(1, a), (1, b), (2, a), (b, b)}\n",
      "2. {(1, a), (2, a), (1, b), (2, b)}\n",
      "3. {(a, 1), (a, 2), (b, 1), (b, 2)}\n",
      "4. {(1, 1), (2, 2), (a, a), (b, b)}\n",
      "\n",
      "Correct answer: 2\n",
      "AI: Student answer: 2\n",
      "Human: Question:\n",
      "If A and B are two sets, and A × B consists of 6 elements: If three elements of A × B are (2, 5) (3, 7) (4, 7) then A × B=____.\n",
      "\n",
      "Options:\n",
      "1. {(2, 5), (2, 7), (3, 5), (3, 7), (3,4), (4,3)}\n",
      "2. {(2, 5), (2, 7), (3, 5), (3, 7), (4,5), (4,7)}\n",
      "3. {(2, 5), (3, 7), (5, 5), (4, 7), (2,7), (3,5)}\n",
      "4. {(2, 2), (7, 7), (5, 5), (3, 3), (4, 4),(4,7)}\n",
      "\n",
      "Correct answer: 2\n",
      "8\n",
      "[SystemMessage(content='You are a student working on a database systems exam (Department of Computer Science), containing multiple choice questions. You are shown a set of questions that you answered earlier in the exam, together with the correct answers and your student answers. Analyse your responses to the questions and identify the possible misconceptions that led to answering incorrectly. Inspect the new question and think how you would answer it as a student. If you answer incorrectly, explain which misconception leads to selecting that answer. If you answer correctly, explain why you think the answer is correct. Provide your answer as an integer in the range 1-4. Wrap the output in `json` tags\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Answer to a multiple-choice question.\", \"properties\": {\"explanation\": {\"description\": \"Misconception if incorrectly answered; motivation if correctly answered\", \"title\": \"Explanation\", \"type\": \"string\"}, \"student_answer\": {\"description\": \"The student\\'s answer to the question, as an integer (1-4)\", \"title\": \"Student Answer\", \"type\": \"integer\"}}, \"required\": [\"explanation\", \"student_answer\"]}\\n```', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\nConsider a relation schema <font  color=\"blue\">Course(courseID,courseName,semester)</font>. Here the courseID, courseName and semester are __________.\\n\\nOptions:\\n1. Attributes\\n2. Relations\\n3. Instances\\n4. Tuples\\n\\nCorrect answer: 1', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 1', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\nThe order of tuples in a relation is ____. The order of attributes in a relation is _________.\\n\\nOptions:\\n1. Not important; Not important\\n2. Important; Important\\n3. Not important; Important\\n4. Important; Not important\\n\\nCorrect answer: 3', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 3', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\n_________ is the sets of all possible values for an attribute.\\n\\nOptions:\\n1. Table\\n2. Tuple\\n3. Domain\\n4. Attribute\\n\\nCorrect answer: 3', additional_kwargs={}, response_metadata={}), AIMessage(content='Student answer: 3', additional_kwargs={}, response_metadata={}), HumanMessage(content='Question:\\nIf A and B are two sets, and A × B consists of 6 elements: If three elements of A × B are (2, 5) (3, 7) (4, 7) then A × B=____.\\n\\nOptions:\\n1. {(2, 5), (2, 7), (3, 5), (3, 7), (3,4), (4,3)}\\n2. {(2, 5), (2, 7), (3, 5), (3, 7), (4,5), (4,7)}\\n3. {(2, 5), (3, 7), (5, 5), (4, 7), (2,7), (3,5)}\\n4. {(2, 2), (7, 7), (5, 5), (3, 3), (4, 4),(4,7)}\\n\\nCorrect answer: 2', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "system_prompt_raw = (\n",
    "    \"You are a student working on {exam_type}, containing multiple choice questions. \"\n",
    "    \"You are shown a set of questions that you answered earlier in the exam, together with the correct answers and your student answers. \"\n",
    "    \"Analyse your responses to the questions and identify the possible misconceptions that led to answering incorrectly. \"\n",
    "    \"Inspect the new question and think how you would answer it as a student. \"\n",
    "    \"If you answer incorrectly, explain which misconception leads to selecting that answer. \"\n",
    "    \"If you answer correctly, explain why you think the answer is correct. \"\n",
    "    \"Provide your answer as an integer in the range 1-4. \"\n",
    ")\n",
    "if not SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    system_prompt_raw += \"Wrap the output in `json` tags\\n{format_instructions}\"\n",
    "    # Set up a parser\n",
    "    parser = PydanticOutputParser(pydantic_object=MCQAnswer)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_raw),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions(),\n",
    "          exam_type=\"a database systems exam (Department of Computer Science)\")\n",
    "\n",
    "print(\n",
    "    final_prompt.invoke(\n",
    "        input=list_val[0],\n",
    "    ).to_string()\n",
    ")\n",
    "out = final_prompt.invoke(input=list_val[0]).to_messages()\n",
    "print(len(out))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-03-18 11:59:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mBuilding model                \u001b[0m \u001b[36mname\u001b[0m=\u001b[35molmo2:7b\u001b[0m \u001b[36mprovider\u001b[0m=\u001b[35mollama\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = build_model(model_cfg=model_cfg)\n",
    "if SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    model = model.with_structured_output(MCQAnswer)\n",
    "\n",
    "# chain\n",
    "chain = final_prompt | model\n",
    "if not SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    chain = chain.pipe(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCQAnswer(explanation='The Cartesian product A \\times B includes all possible pairs where the first element is from set A and the second element is from set B. Given three pairs (2, 5), (3, 7), and (4, 7), we know that there must be at least one pair for each element in A (2 and 3) and at least one pair for each element in B (5, 7). Therefore, A \\times B contains the pairs: (2, 5), (3, 7), and (4, 7). The correct option includes all these pairs plus one more pair for each of the remaining elements in A (which are 1 and 4) and one pair for each element in B (which are 6 and 9). Thus, the complete set is {(2, 5), (2, 7), (3, 5), (3, 7), (4, 5), (4, 7), (1, 6), (3, 6), (5, 6), (4, 9), (7, 9)} which matches option 2.', student_answer=2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "val_example = list_val[0]\n",
    "val_output = chain.invoke(val_example)\n",
    "val_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add func to only print input (also printing output can be confusing)\n",
    "def print_example(example: dict) -> None:\n",
    "    \"\"\"Print single example.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : dict\n",
    "        Example dictionary with 'input' and 'output' keys.\n",
    "    \"\"\"\n",
    "    text = (\n",
    "        \"#\" * 40\n",
    "        + f\"\\nINPUT\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\n{example['input']}\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\nOUTPUT\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\n{example['output']}\\n\"\n",
    "    )\n",
    "    print(text)\n",
    "\n",
    "\n",
    "print_example(list_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_virtual_pretesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
