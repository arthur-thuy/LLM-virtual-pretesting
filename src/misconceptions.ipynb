{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "# related third party imports\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import structlog\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from yacs.config import CfgNode\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# local application/library specific imports\n",
    "from example_selector.example_selector import (\n",
    "    RandomExampleSelector,\n",
    "    StudentIDRandomExampleSelector,\n",
    ")\n",
    "from data_loader.data_loader import DataLoader\n",
    "from tools.constants import (\n",
    "    SILVER_DIR,\n",
    "    TRAIN,\n",
    "    VALIDATION,\n",
    "    TEST,\n",
    "    MODEL_STRUCTURED_OUTPUT,\n",
    "    VALLARGE,\n",
    "    VALSMALL,\n",
    ")\n",
    "from prompt.utils import (\n",
    "    df_to_listdict,\n",
    ")\n",
    "from model.build import build_model\n",
    "from example_formatter.build import build_example_formatter\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "# Reload the variables in your '.env' file (override the existing variables)\n",
    "dotenv.load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INPUTS ###\n",
    "MODEL_NAME = \"llama3\"  # \"olmo2:7b\"  # \"gpt-4o-mini\"  # \"llama3.2\"\n",
    "MODEL_PROVIDER = \"ollama\"  # \"openai\"  # \n",
    "SUPPORTS_STRUCTURED_OUTPUT = MODEL_STRUCTURED_OUTPUT[MODEL_NAME]\n",
    "RUN_LARGE_VAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = CfgNode(\n",
    "    {\n",
    "        \"NAME\": MODEL_NAME,\n",
    "        \"PROVIDER\": MODEL_PROVIDER,\n",
    "        \"TEMPERATURE\": 0.5,\n",
    "        \"MAX_TOKENS\": None,\n",
    "        \"TIMEOUT\": None,\n",
    "        \"MAX_RETRIES\": None,\n",
    "    }\n",
    ")\n",
    "example_formatter_cfg = CfgNode(\n",
    "    {\n",
    "        \"NAME\": \"A\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_loader = DataLoader(read_dir=SILVER_DIR, dataset_name=\"dbe_kt22\")\n",
    "datasets = data_loader.read_splitted_data(join_key=\"question_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # dataframes\n",
    "# df_train = apply_prompt_fmt(\n",
    "#     df=dataset[TRAIN], input_fmt=human_format_input, output_fmt=human_format_output\n",
    "# )\n",
    "# df_val = apply_prompt_fmt(\n",
    "#     df=dataset[VALIDATION], input_fmt=human_format_input, output_fmt=human_format_output\n",
    "# )\n",
    "# df_test = apply_prompt_fmt(\n",
    "#     df=dataset[TEST], input_fmt=human_format_input, output_fmt=human_format_output\n",
    "# )\n",
    "\n",
    "# # list of dicts\n",
    "# list_train = df_to_listdict(df_train)\n",
    "# list_val = df_to_listdict(df_val)\n",
    "# list_test = df_to_listdict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose small or large validation set\n",
    "if RUN_LARGE_VAL:\n",
    "    datasets[VALIDATION] = datasets.pop(VALLARGE)\n",
    "    datasets.pop(VALSMALL)\n",
    "else:\n",
    "    datasets[VALIDATION] = datasets.pop(VALSMALL)\n",
    "    datasets.pop(VALLARGE)\n",
    "logger.info(\n",
    "    \"Choosing validation set\",\n",
    "    name=(VALLARGE if RUN_LARGE_VAL else VALSMALL),\n",
    "    num_interactions=len(datasets[VALIDATION]),\n",
    ")\n",
    "\n",
    "# dataframes\n",
    "datasets_fmt = build_example_formatter(\n",
    "    example_formatter_cfg=example_formatter_cfg,\n",
    "    datasets=datasets,\n",
    ")\n",
    "\n",
    "# list of dicts\n",
    "list_train = df_to_listdict(datasets_fmt[TRAIN])\n",
    "list_val = df_to_listdict(datasets_fmt[VALIDATION])\n",
    "list_test = df_to_listdict(datasets_fmt[TEST])  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_fmt[VALIDATION].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example selector\n",
    "\n",
    "NOTE: I need OpenAI credits to use the OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import click\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from tools.constants import QUESTION_ID, Q_TEXT\n",
    "\n",
    "EMBEDDINGS_DIM = {\"llama3\": 4096}\n",
    "EMBEDDING_PROVIDER = {\"llama3\": \"ollama\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# index_name = \"llama3\"  # change if desired\n",
    "\n",
    "# pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "#     pc.create_index(\n",
    "#         name=index_name,\n",
    "#         dimension=EMBEDDINGS_DIM[model_cfg.NAME],\n",
    "#         metric=\"cosine\",\n",
    "#         spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "#     )\n",
    "#     while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "#         time.sleep(1)\n",
    "\n",
    "# index = pc.Index(index_name)\n",
    "\n",
    "# embeddings = OllamaEmbeddings(model=\"llama3\")  # TODO: make dynamic\n",
    "\n",
    "# vector_store = PineconeVectorStore(index=index, embedding=embeddings, namespace=\"dbe_kt22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare data for vector store\n",
    "# vector_input_df = datasets[TRAIN].drop_duplicates(subset=\"question_id\")\n",
    "\n",
    "# vector_input_doc = [\n",
    "#     Document(\n",
    "#         page_content=row[\"q_text\"],\n",
    "#         metadata={\n",
    "#             \"question_id\": str(row[\"question_id\"]),\n",
    "#         },\n",
    "#     )\n",
    "#     for _, row in vector_input_df.iterrows()\n",
    "# ]\n",
    "# vector_input_id = vector_input_df[\"question_id\"].astype(str).tolist()\n",
    "\n",
    "# print(vector_input_doc)\n",
    "# len(vector_input_doc)\n",
    "# print(vector_input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = vector_store.add_documents(documents=vector_input_doc, ids=vector_input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"llama-text-embed-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from pinecone import Pinecone\n",
    "# from model.build import build_embedding\n",
    "\n",
    "\n",
    "# def get_vector_store(\n",
    "#     index_name: str, embedding_name: str, namespace: str\n",
    "# ) -> PineconeVectorStore:\n",
    "#     \"\"\"Get the Pinecode vector store.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     index_name : str\n",
    "#         Index name\n",
    "#     embedding_name : str\n",
    "#         Embedding name\n",
    "#     namespace : str\n",
    "#         Index namespace\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     PineconeVectorStore\n",
    "#         The Pinecone vector store.\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     ValueError\n",
    "#         If the index does not exist.\n",
    "#     \"\"\"\n",
    "#     pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "#     if not pc.has_index(index_name):\n",
    "#         raise ValueError(f\"Index {index_name} does not exist.\")\n",
    "#     index = pc.Index(index_name)\n",
    "#     embedding = build_embedding(\n",
    "#         embedding_name=embedding_name, provider=EMBEDDING_PROVIDER[embedding_name]\n",
    "#     )\n",
    "#     vector_store = PineconeVectorStore(\n",
    "#         index=index, embedding=embedding, namespace=namespace\n",
    "#     )\n",
    "#     logger.info(\n",
    "#         f\"Loaded Pinecone vector store\", index_name=index_name, namespace=namespace\n",
    "#     )\n",
    "#     return vector_store\n",
    "\n",
    "\n",
    "# EMBEDDING_NAMES = {\"llama3\": \"llama3\"}\n",
    "\n",
    "\n",
    "# class StudentIDSemanticExampleSelector(BaseExampleSelector):\n",
    "#     \"\"\"Filter examples of the same student_id and select based on semantic similarity.\"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self, examples: list, k: int, index_name: str, model_name: str, namespace: str\n",
    "#     ) -> None:\n",
    "#         \"\"\"Initialize the example selector.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         k : int\n",
    "#             k-shot prompting\n",
    "#         index_name : str\n",
    "#             The name of the Pinecone index.\n",
    "#         model_name : str\n",
    "#             The name of the LLM.\n",
    "#         namespace : str\n",
    "#             The namespace of the Pinecone index.\n",
    "#         \"\"\"\n",
    "#         self.examples = examples\n",
    "#         self.k = k\n",
    "\n",
    "#         embedding_name = EMBEDDING_NAMES[model_name]\n",
    "#         self.vectorstore = get_vector_store(\n",
    "#             index_name=index_name, embedding_name=embedding_name, namespace=namespace\n",
    "#         )\n",
    "\n",
    "#     def add_example(self, example: list) -> None:\n",
    "#         self.examples.append(example)\n",
    "\n",
    "#     def select_examples(self, input_variables: dict) -> list[dict[str, str]]:\n",
    "#         \"\"\"Select examples based on semantic similarity.\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         input_variables : dict[str, str]\n",
    "#             A dict containing info about a single observation.\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         list[dict[str, str]]\n",
    "#             The selected examples.\n",
    "#         \"\"\"\n",
    "#         # information of target observation\n",
    "#         student_id = input_variables[\"student_id\"]\n",
    "#         question_id = input_variables[\"question_id\"]\n",
    "#         q_text = input_variables[\"q_text\"]\n",
    "\n",
    "#         # find all questions answered by this student\n",
    "#         student_interactions = [\n",
    "#             interact\n",
    "#             for interact in self.examples\n",
    "#             if interact[\"student_id\"] == student_id\n",
    "#         ]\n",
    "#         q_answered = set([interact[\"question_id\"] for interact in student_interactions])\n",
    "#         q_answered = list(\n",
    "#             map(str, q_answered - {question_id})\n",
    "#         )  # NOTE: remove current question_id\n",
    "#         print(f\"{q_answered=}\")  # TODO: remove\n",
    "\n",
    "#         # semantic search on question text\n",
    "#         results = self.vectorstore.similarity_search(\n",
    "#             query=q_text,\n",
    "#             k=self.k,\n",
    "#             filter={\"question_id\": {\"$in\": q_answered}},\n",
    "#         )\n",
    "#         question_ids_selected = list(\n",
    "#             map(int, [res.metadata[\"question_id\"] for res in results])\n",
    "#         )\n",
    "#         print(f\"{question_ids_selected=}\")  # TODO: remove\n",
    "\n",
    "#         # find interactions of selected question_ids and student_id\n",
    "#         interactions_selected = [\n",
    "#             interact\n",
    "#             for interact in self.examples\n",
    "#             if (\n",
    "#                 interact[\"question_id\"] in question_ids_selected\n",
    "#                 and interact[\"student_id\"] == student_id\n",
    "#             )\n",
    "#         ]\n",
    "#         # if a Q has multiple interactions, randomly select one\n",
    "#         if len(interactions_selected) > self.k:\n",
    "#             # find duplicate Q IDs\n",
    "#             question_ids_interacted = np.array(\n",
    "#                 [interact[\"question_id\"] for interact in interactions_selected]\n",
    "#             )\n",
    "#             unique, counts = np.unique(question_ids_interacted, return_counts=True)\n",
    "#             duplicate_q_ids = unique[np.where(counts > 1)]\n",
    "\n",
    "#             # sample from duplicate Q IDs\n",
    "#             for q_id in duplicate_q_ids:\n",
    "#                 # find indexes to remove\n",
    "#                 idxs = np.where(question_ids_interacted == q_id)[0].tolist()\n",
    "#                 idx_to_remove = random.sample(idxs, len(idxs) - 1)\n",
    "#                 for idx in idx_to_remove:\n",
    "#                     interactions_selected.pop(idx)\n",
    "#         if len(interactions_selected) < self.k:\n",
    "#             raise NotImplementedError(\n",
    "#                 \"TODO: do we randomly select interactions or leave them empty?\"\n",
    "#             )\n",
    "#             # TODO\n",
    "\n",
    "#         return interactions_selected\n",
    "#         # NOTE: can decide to only return input and output\n",
    "#         # return [\n",
    "#         #     {\"input\": interact[\"input\"], \"output\": interact[\"output\"]}\n",
    "#         #     for interact in interactions_selected\n",
    "#         # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_selector = StudentIDSemanticExampleSelector(\n",
    "#     examples=list_train,\n",
    "#     k=2,\n",
    "#     index_name=\"llama3\",\n",
    "#     model_name=model_cfg.NAME,\n",
    "#     namespace=\"dbe_kt22\",\n",
    "# )\n",
    "# example_selector.select_examples(list_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = list_train[:10]\n",
    "# to_vectorize = [example[\"input\"] for example in examples]\n",
    "# # embeddings = OpenAIEmbeddings()\n",
    "# embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "# vectorstore = Chroma.from_texts(\n",
    "#     texts=to_vectorize,\n",
    "#     embedding=embeddings,\n",
    "#     metadatas=examples,\n",
    "#     persist_directory=os.path.join(\"output\", \"vectorstore\", \"chroma_langchain_db\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: texts depend on the example formatter used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_selector = SemanticSimilarityExampleSelector(\n",
    "#     vectorstore=vectorstore,\n",
    "#     k=1\n",
    "# )\n",
    "# example_selector.select_examples({\"input\": list_val[0][\"input\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_selector = SemanticSimilarityExampleSelector(\n",
    "#     vectorstore=vectorstore,\n",
    "#     k=2,\n",
    "# )\n",
    "\n",
    "# # The prompt template will load examples by passing the input do the `select_examples` method\n",
    "# example_selector.select_examples({\"input\": \"horse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the selector with k=3 for 3-shot prompting\n",
    "# example_selector = RandomExampleSelector(examples=list_train, k=3)\n",
    "# example_selector.select_examples({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select examples of a specific student\n",
    "# example_selector = StudentIDExampleSelector(examples=list_train, k=3)\n",
    "# example_selector.select_examples({\"student_id\": 395})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic\n",
    "class MCQAnswer(BaseModel):\n",
    "    \"\"\"Answer to a multiple-choice question.\"\"\"\n",
    "\n",
    "    explanation: str = Field(\n",
    "        description=\"Misconception if incorrectly answered; motivation if correctly answered\"\n",
    "    )\n",
    "    student_answer: int = Field(\n",
    "        description=\"The student's answer to the question, as an integer (1-4)\"\n",
    "    )\n",
    "    # difficulty: str = Field(description=\"The difficulty level of the question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the few-shot prompt.\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    # The input variables select the values to pass to the example_selector\n",
    "    input_variables=[\"student_id\"],  # TODO: do not hardcode\n",
    "    example_selector=example_selector,\n",
    "    # Define how each example will be formatted.\n",
    "    # In this case, each example will become 2 messages:\n",
    "    # 1 human, and 1 AI\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")\n",
    "\n",
    "out = few_shot_prompt.invoke(input=list_val[0]).to_messages()\n",
    "print(len(out))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_raw = (\n",
    "    \"You are a student working on {exam_type}, containing multiple choice questions. \"\n",
    "    \"You are shown a set of questions that you answered earlier in the exam, together with the correct answers and your student answers. \"\n",
    "    \"Analyse your responses to the questions and identify the possible misconceptions that led to answering incorrectly. \"\n",
    "    \"Inspect the new question and think how you would answer it as a student. \"\n",
    "    \"If you answer incorrectly, explain which misconception leads to selecting that answer. \"\n",
    "    \"If you answer correctly, explain why you think the answer is correct. \"\n",
    "    \"Provide your answer as an integer in the range 1-4. \"\n",
    ")\n",
    "# Set up a parser (not used if model supports structured output)\n",
    "parser = PydanticOutputParser(pydantic_object=MCQAnswer)\n",
    "if not SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    system_prompt_raw += \"Wrap the output in `json` tags\\n{format_instructions}\"\n",
    "\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt_raw),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ").partial(\n",
    "    format_instructions=parser.get_format_instructions(),\n",
    "    exam_type=\"a database systems exam (Department of Computer Science)\",\n",
    ")\n",
    "\n",
    "# print(\n",
    "#     final_prompt.invoke(\n",
    "#         input=list_val[0],\n",
    "#     ).to_string()\n",
    "# )\n",
    "out = final_prompt.invoke(input=list_val[0]).to_messages()\n",
    "print(len(out))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = build_model(model_cfg=model_cfg)\n",
    "if SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    model = model.with_structured_output(MCQAnswer, include_raw=True)\n",
    "\n",
    "# chain\n",
    "chain = final_prompt | model\n",
    "# if not SUPPORTS_STRUCTURED_OUTPUT:\n",
    "#     chain = chain.pipe(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt.utils import validate_output\n",
    "\n",
    "# run model in batch\n",
    "preds_raw = chain.batch(list_val[:10])\n",
    "if SUPPORTS_STRUCTURED_OUTPUT:\n",
    "    # get all raw outputs\n",
    "    preds_raw = [output[\"raw\"] for output in preds_raw]\n",
    "preds_validated = validate_output(preds_raw, schema=MCQAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = np.array([output.student_answer for output in preds_validated])\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_student = datasets[VALIDATION][\"student_option_id\"].to_numpy()[:10]\n",
    "y_val_student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_true = datasets[VALIDATION][\"correct_option_id\"].to_numpy()[:10]\n",
    "y_val_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_student_pred = accuracy_score(y_true=y_val_student, y_pred=y_val_pred)\n",
    "acc_true_student = accuracy_score(y_true=y_val_true, y_pred=y_val_student)\n",
    "acc_true_pred = accuracy_score(y_true=y_val_true, y_pred=y_val_pred)\n",
    "\n",
    "print(f\"{acc_student_pred = }\")\n",
    "print(f\"{acc_true_student = }\")\n",
    "print(f\"{acc_true_pred = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add func to only print input (also printing output can be confusing)\n",
    "def print_example(example: dict) -> None:\n",
    "    \"\"\"Print single example.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example : dict\n",
    "        Example dictionary with 'input' and 'output' keys.\n",
    "    \"\"\"\n",
    "    text = (\n",
    "        \"#\" * 40\n",
    "        + f\"\\nINPUT\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\n{example['input']}\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\nOUTPUT\\n\"\n",
    "        + \"#\" * 40\n",
    "        + f\"\\n{example['output']}\\n\"\n",
    "    )\n",
    "    print(text)\n",
    "\n",
    "\n",
    "print_example(list_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_virtual_pretesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
