{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "# /\n",
    "\n",
    "# related third party imports\n",
    "import structlog\n",
    "\n",
    "# local application/library specific imports\n",
    "from tools.configurator import (\n",
    "    get_configs_out,\n",
    "    get_config_ids,\n",
    ")\n",
    "from tools.analyzer import (\n",
    "    print_table_from_dict,\n",
    "    print_df_from_dict,\n",
    "    get_results_dict,\n",
    "    merge_all_results,\n",
    "    create_config_id_print,\n",
    "    get_config_df,\n",
    "    get_llm_student_preds,\n",
    ")\n",
    "from tools.plotter import (\n",
    "    plot_llm_student_confusion,\n",
    "    plot_kt_confusion,\n",
    "    plot_level_correctness,\n",
    ")\n",
    "\n",
    "\n",
    "logger = structlog.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "EXP_NAME = (\n",
    "    # \"replication_gemini_20250628-091441\"\n",
    "    # \"replication_sonnet_20250629-084225\"\n",
    "    # \"replication_ollama_gemma_20250628-142438\"\n",
    "    # \"replication_ollama_qwen_20250627-164511\"\n",
    "    # \"replication_o3_o4_20250628-143855\"\n",
    "    # \"replication_cloud_others_20250624-184518\"\n",
    "    # \"replication_ollama_20250624-210701\"\n",
    "    # \"replication_cloud_20250624-155854\"\n",
    "    # \"replication_ollama_20250624-133329\"\n",
    "    # \"replication_misconceptions_20250806-170742\"\n",
    "    # \"replication_misconceptions_tryout_20250807-152718\"\n",
    "    # \"replication_misconceptions_20250808-171245\"\n",
    "    # \"replication_misconceptions_20250811-224100\"\n",
    "    # \"replication_snippets_20250812-090413\"\n",
    "    \"replication_misconceptions_20250812-111219\"\n",
    ")\n",
    "EXCLUDE_METRICS = [\n",
    "    \"val_acc_true_student\",\n",
    "    \"val_acc_true_pred\",\n",
    "    \"val_f1_true_student\",\n",
    "    \"val_f1_true_pred\",\n",
    "    \"val_f1_student_pred\",\n",
    "    \"val_f1_kt\",\n",
    "]\n",
    "LEGEND_EXACT = True\n",
    "PROBLEM_TYPE = \"replicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC2LEGEND_DICT = {\n",
    "    \"val_acc_student_pred\": \"val acc\",\n",
    "    \"val_acc_true_student\": \"val acc student -> true\",\n",
    "    \"val_acc_true_pred\": \"val acc LLM -> true\",\n",
    "    \"val_f1_student_pred\": \"val f1 LLM -> student\",\n",
    "    \"val_f1_true_student\": \"val f1 student -> true\",\n",
    "    \"val_f1_true_pred\": \"val f1 LLM -> true\",\n",
    "    \"val_acc_kt\": \"val acc (KT)\",\n",
    "    \"val_f1_kt\": \"val f1 LLM -> student (KT)\",\n",
    "    \"val_prop_invalid\": \"val prop invalid\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_configs_out(EXP_NAME)\n",
    "config_ids = get_config_ids(configs, problem_type=PROBLEM_TYPE)\n",
    "config_dict = {config_id: cfg for config_id, cfg in zip(config_ids, configs)}\n",
    "\n",
    "CONFIG2LEGEND_DICT = {\n",
    "    config_id: create_config_id_print(config_id) for config_id in config_ids\n",
    "}\n",
    "legend_kwargs = {\n",
    "    \"config2legend\": CONFIG2LEGEND_DICT,\n",
    "    \"legend_exact\": LEGEND_EXACT,\n",
    "    \"metric2legend\": METRIC2LEGEND_DICT,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge results for all configs\n",
    "run_id_dict = merge_all_results(EXP_NAME, config_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Val/Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = get_results_dict(\n",
    "    exp_name=EXP_NAME,\n",
    "    config_ids=config_ids,\n",
    "    run_id=None,\n",
    ")\n",
    "# # NOTE: print paper-like table with this code\n",
    "# print_table_from_dict(\n",
    "#     eval_dict=results_dict,\n",
    "#     exp_name=EXP_NAME,\n",
    "#     exclude_metrics=EXCLUDE_METRICS,\n",
    "#     decimals=3,\n",
    "#     **legend_kwargs,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: print dataframe\n",
    "df = print_df_from_dict(\n",
    "    eval_dict=results_dict,\n",
    "    exp_name=EXP_NAME,\n",
    "    exclude_metrics=EXCLUDE_METRICS,\n",
    "    **legend_kwargs,\n",
    "    # save=True,\n",
    "    # save_kwargs={\"fname\": os.path.join(\"output\", EXP_NAME, \"results.csv\")},\n",
    ")\n",
    "\n",
    "df_config = get_config_df(config_dict)\n",
    "\n",
    "# mean\n",
    "df_mean = df.xs(\"mean\", axis=1, level=1, drop_level=True)\n",
    "df_results = df_mean.merge(df_config, how=\"left\", on=\"config_id\")\n",
    "df_results = df_results.reindex(\n",
    "    columns=(\n",
    "        list(df_config.columns)\n",
    "        + list([a for a in df_mean.columns if a not in df_config.columns])\n",
    "    )\n",
    ")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error\n",
    "df_stderr = df.xs(\"stderr\", axis=1, level=1, drop_level=True)\n",
    "df_stderr = df_stderr.merge(df_config, how=\"left\", on=\"config_id\")\n",
    "df_stderr = df_stderr.reindex(\n",
    "    columns=(\n",
    "        list(df_config.columns)\n",
    "        + list([a for a in df_stderr.columns if a not in df_config.columns])\n",
    "    )\n",
    ")\n",
    "df_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect average performance per config value\n",
    "FEATURE = \"num_examples\"\n",
    "df_results.groupby(FEATURE).agg({\"val acc\": \"mean\", \"val acc (KT)\": \"mean\", \"val_monotonicity\": \"mean\"}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect average performance per config value\n",
    "FEATURE = \"model\"\n",
    "df_results.groupby(FEATURE).agg({\"val acc\": \"mean\", \"val acc (KT)\": \"mean\", \"val_monotonicity\": \"mean\"}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect average performance per config value\n",
    "FEATURE = \"temp\"\n",
    "df_results.groupby(FEATURE).agg({\"val acc\": \"mean\", \"val acc (KT)\": \"mean\", \"val_monotonicity\": \"mean\"}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect average performance per config value\n",
    "FEATURE = \"prompt\"\n",
    "df_results.groupby(FEATURE).agg({\"val acc\": \"mean\", \"val acc (KT)\": \"mean\", \"val_monotonicity\": \"mean\"}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect average performance per config value\n",
    "FEATURE = \"example_selec\"\n",
    "df_results.groupby(FEATURE).agg({\"val acc\": \"mean\", \"val acc (KT)\": \"mean\", \"val_monotonicity\": \"mean\"}).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices\n",
    "## LLM vs student performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single config\n",
    "# config_id = \"qwen3:8b~T_0.0~SO_teacher~SP_replicate_teacher_avocado~EF_quotes~ES_studentid_random3\"  # TODO\n",
    "# if config_id not in config_ids:\n",
    "#     logger.error(f\"Config ID not available\", config_id=config_id)\n",
    "# else:\n",
    "#     preds_dict = get_llm_student_preds(\n",
    "#         exp_name=EXP_NAME,\n",
    "#         config_id=config_id,\n",
    "#         run_id=1,\n",
    "#         split=\"val\",\n",
    "#     )\n",
    "#     plot_llm_student_confusion(\n",
    "#         preds_dict,\n",
    "#         config_id=config_id,\n",
    "#         normalize=\"all\",\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all configs\n",
    "for config_id in config_ids:\n",
    "    preds_dict = get_llm_student_preds(\n",
    "        exp_name=EXP_NAME,\n",
    "        config_id=config_id,\n",
    "        run_id=1,\n",
    "        split=\"val\",\n",
    "        problem_type=PROBLEM_TYPE,\n",
    "    )\n",
    "    plot_llm_student_confusion(\n",
    "        preds_dict,\n",
    "        config_id=config_id,\n",
    "        normalize=\"all\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all configs\n",
    "for config_id in config_ids:\n",
    "    preds_dict = get_llm_student_preds(\n",
    "        exp_name=EXP_NAME,\n",
    "        config_id=config_id,\n",
    "        run_id=1,\n",
    "        split=\"val\",\n",
    "        problem_type=PROBLEM_TYPE,\n",
    "    )\n",
    "    plot_kt_confusion(\n",
    "        preds_dict,\n",
    "        config_id=config_id,\n",
    "        normalize=\"all\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all configs\n",
    "for config_id in config_ids:\n",
    "    preds_dict = get_llm_student_preds(\n",
    "        exp_name=EXP_NAME,\n",
    "        config_id=config_id,\n",
    "        run_id=1,\n",
    "        split=\"val\",\n",
    "        problem_type=PROBLEM_TYPE,\n",
    "    )\n",
    "    plot_level_correctness(\n",
    "        preds_dict,\n",
    "        problem_type=PROBLEM_TYPE,\n",
    "        config_id=config_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
